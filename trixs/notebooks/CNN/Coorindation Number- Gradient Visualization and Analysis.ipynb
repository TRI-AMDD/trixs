{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T02:10:26.422279Z",
     "start_time": "2019-08-13T02:10:21.888501Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Machine learning:\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv1D, \\\n",
    " MaxPooling1D, Flatten\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import json\n",
    "import talos as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T02:10:27.253010Z",
     "start_time": "2019-08-13T02:10:26.425152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def onehot_reverse(y):\n",
    "    \"\"\"Takes a one-hot encoded list `y` and returns a numpy array of dimension\n",
    "    (m, c) (see oneshot_forward) compatible with a Keras ML algorithm.\"\"\"\n",
    "\n",
    "    m = len(y)\n",
    "    c = max(y) + 1\n",
    "\n",
    "    yf = np.zeros((m, c))\n",
    "\n",
    "    for i, yy in enumerate(y):\n",
    "      yf[i, yy] = 1\n",
    "\n",
    "    return yf\n",
    "data = []\n",
    "for line in open('./Ti_O_XY.json', 'r'):\n",
    "    data.append(json.loads(line))\n",
    "    \n",
    "print(\"Total of %i data points\" % len(data))\n",
    "print(\"Keys are %a\" % data[0].keys())\n",
    "\n",
    "# Using mu here not mu0\n",
    "all_feature_lens = [len(data[ii]['mu']) == len(data[0]['mu'])\n",
    "                    for ii in range(len(data))]\n",
    "print(\"All features same length: %s\" % np.all(np.array(all_feature_lens)))\n",
    "# Only take 4, 5 and 6 coordinated:\n",
    "to_ignore = [ii for ii in range(len(data)) if data[ii]['coordination'] not in [4, 5, 6]]\n",
    "features = np.array([data[ii]['mu'] for ii in range(len(data)) if ii not in to_ignore])\n",
    "\n",
    "# Minus 4 so that 6 - 4 = 2, 5 - 4 = 1 and 4 - 4 = 0; ensures that my one-hot\n",
    "# decoder/encoder system can work properly!\n",
    "_targets = np.array([data[ii]['coordination'] - 4 for ii in range(len(data)) if ii not in to_ignore])\n",
    "targets = onehot_reverse(_targets)\n",
    "print(features.shape, targets.shape)\n",
    "\n",
    "\n",
    "# Generate train/validate/test splits\n",
    "RANDSTATE=555\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "  train_test_split(features, targets, test_size=0.1,\n",
    "                   random_state=RANDSTATE)\n",
    "x_train, x_valid, y_train, y_valid = \\\n",
    "  train_test_split(x_train, y_train, test_size=0.1,\n",
    "                   random_state=RANDSTATE)\n",
    "print(\"training    %s ~ %s\"\n",
    "      % ((x_train.shape), (y_train.shape)))\n",
    "print(\"validation  %s ~ %s\"\n",
    "      % ((x_valid.shape), (y_valid.shape)))\n",
    "print(\"testing     %s ~ %s\"\n",
    "      % ((x_test.shape), (y_test.shape)))\n",
    "\n",
    "# Want to normalize the targets first\n",
    "y_train = y_train/np.max(y_train, axis=1, keepdims=True)\n",
    "y_valid = y_valid/np.max(y_valid, axis=1, keepdims=True)\n",
    "y_test = y_test/np.max(y_test, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "train_feature_mean = np.mean(np.mean(x_train, axis=0))\n",
    "train_feature_std = np.mean(np.std(x_train, axis=0))\n",
    "\n",
    "valid_feature_mean = np.mean(np.mean(x_valid, axis=0))\n",
    "valid_feature_std = np.mean(np.std(x_valid, axis=0))\n",
    "\n",
    "test_feature_mean = np.mean(np.mean(x_test, axis=0))\n",
    "test_feature_std = np.mean(np.std(x_test, axis=0))\n",
    "\n",
    "\n",
    "print(\"~~~~~~~~~~~~ Mean +/- Stdev before ~~~~~~~~~~~~~~\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Train features %.03f +/- %.03f\"\n",
    "      % (train_feature_mean, train_feature_std))\n",
    "print(\"Valid features %.03f +/- %.03f\"\n",
    "      % (valid_feature_mean, valid_feature_std))\n",
    "print(\"Test features  %.03f +/- %.03f\"\n",
    "      % (test_feature_mean, test_feature_std))\n",
    "\n",
    "\n",
    "# Generate a feature and target scaler\n",
    "feature_scaler = StandardScaler().fit(x_train)\n",
    "\n",
    "# Utilize that scaler on the datasets\n",
    "\"\"\"\n",
    "x_train = feature_scaler.transform(x_train)\n",
    "x_valid = feature_scaler.transform(x_valid)\n",
    "x_test = feature_scaler.transform(x_test)\n",
    "\n",
    "train_feature_mean = np.mean(np.mean(x_train, axis=0))\n",
    "train_feature_std = np.mean(np.std(x_train, axis=0))\n",
    "\n",
    "valid_feature_mean = np.mean(np.mean(x_valid, axis=0))\n",
    "valid_feature_std = np.mean(np.std(x_valid, axis=0))\n",
    "\n",
    "test_feature_mean = np.mean(np.mean(x_test, axis=0))\n",
    "test_feature_std = np.mean(np.std(x_test, axis=0))\n",
    "\n",
    "print(\"~~~~~~~~~~~~~ Mean +/- Stdev after ~~~~~~~~~~~~~~\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Train features %.03f +/- %.03f\"\n",
    "      % (train_feature_mean, train_feature_std))\n",
    "print(\"Valid features %.03f +/- %.03f\"\n",
    "      % (valid_feature_mean, valid_feature_std))\n",
    "print(\"Test features  %.03f +/- %.03f\"\n",
    "      % (test_feature_mean, test_feature_std))\n",
    "\"\"\";\n",
    "\n",
    "def classification_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    # Params is the vessel that will carry the optimzation parameters\n",
    "    dropout = params['dropout']\n",
    "    act = params['activation_function']\n",
    "    optimizer = params['optimizer']\n",
    "\n",
    "    #layers = params['layers']\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # CNN vs. MLP.\n",
    "    if params['cnn']:\n",
    "        x_train = np.expand_dims(x_train, axis=-1)\n",
    "        x_val = np.expand_dims(x_val, axis=-1)\n",
    "        model.add(Conv1D(params['kernel'],\n",
    "                         params['n_filters'],\n",
    "                         strides=params['strides'], padding='valid',\n",
    "                         activation=act,\n",
    "                         input_shape=(x_train.shape[1], 1)))\n",
    "        model.add(MaxPooling1D(pool_size=params['pool_size'],\n",
    "                               strides=None, padding='valid'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(params['layer0'], activation=act))\n",
    "    else:\n",
    "        model.add(Dense(params['layer0'], activation=act,\n",
    "                        input_shape=(x_train.shape[1],)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "    # note the change here relative to the regresion problem\n",
    "    model.add(Dense(params['layer1'], activation=act))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(params['layer2'], activation=act))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(loss=params['loss_function'], optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                      batch_size=params['batch_size'],\n",
    "                      epochs=params['epochs'],\n",
    "                      validation_data=[x_val, y_val],\n",
    "                      verbose=0,\n",
    "                      shuffle=True)\n",
    "\n",
    "    return history, model\n",
    "\n",
    "use_params = {\n",
    "    'layer0': 90,\n",
    "    'layer1':60, \n",
    "    'layer2':45,\n",
    "    'dropout': 0.1,\n",
    "    'activation_function': 'relu',\n",
    "    'optimizer': 'adam',\n",
    "    'cnn': True,\n",
    "    'kernel': 8,\n",
    "    'n_filters': 10,\n",
    "    'strides': 1,\n",
    "    'pool_size': 2,\n",
    "    'loss_function': 'categorical_crossentropy',\n",
    "    'batch_size': 32,\n",
    "    'epochs':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T02:39:46.388583Z",
     "start_time": "2019-08-13T02:38:44.661428Z"
    }
   },
   "outputs": [],
   "source": [
    "_, the_model =  classification_model(x_train, y_train, x_valid, y_valid, use_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T03:01:43.195343Z",
     "start_time": "2019-08-13T03:01:43.191423Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_layer_output_gradient_simple_target(model,X,target_output):\n",
    "    inputs = model.input\n",
    "    outputs = model.output\n",
    "    focus = model.output[0][target_output]\n",
    "    grad = K.gradients(focus, inputs)[0]\n",
    "    f = K.function([inputs], [outputs,grad])    \n",
    "    return f([X])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T03:01:43.861728Z",
     "start_time": "2019-08-13T03:01:43.853373Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(y_valid[:30])\n",
    "\n",
    "four_candidate = x_valid[4]\n",
    "five_candidate = x_valid[20]\n",
    "#print(y_valid[fi_cnd_i])\n",
    "six_candidate = x_valid[0]\n",
    "#print(x_valid[0:100])\n",
    "print(the_model.predict(four_candidate.reshape(1,100,1)))\n",
    "print(the_model.predict(five_candidate.reshape(1,100,1)))\n",
    "print(the_model.predict(six_candidate.reshape(1,100,1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T03:01:54.564675Z",
     "start_time": "2019-08-13T03:01:44.392978Z"
    }
   },
   "outputs": [],
   "source": [
    "grad_44 = get_layer_output_gradient_simple_target(the_model,four_candidate.reshape(1,100,1),0).reshape(100)\n",
    "grad_45 = get_layer_output_gradient_simple_target(the_model,four_candidate.reshape(1,100,1),1).reshape(100)\n",
    "grad_46 = get_layer_output_gradient_simple_target(the_model,four_candidate.reshape(1,100,1),2).reshape(100)\n",
    "grad_54 = get_layer_output_gradient_simple_target(the_model,five_candidate.reshape(1,100,1),0).reshape(100)\n",
    "grad_55 = get_layer_output_gradient_simple_target(the_model,five_candidate.reshape(1,100,1),1).reshape(100)\n",
    "grad_56 = get_layer_output_gradient_simple_target(the_model,five_candidate.reshape(1,100,1),2).reshape(100)\n",
    "grad_64 = get_layer_output_gradient_simple_target(the_model,six_candidate.reshape(1,100,1),0).reshape(100)\n",
    "grad_65 = get_layer_output_gradient_simple_target(the_model,six_candidate.reshape(1,100,1),1).reshape(100)\n",
    "grad_66 = get_layer_output_gradient_simple_target(the_model,six_candidate.reshape(1,100,1),2).reshape(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T03:08:09.469300Z",
     "start_time": "2019-08-13T03:08:09.043653Z"
    }
   },
   "outputs": [],
   "source": [
    "norm = mpl.colors.Normalize(vmin=min(grad_46), vmax=max(grad_46))\n",
    "grad_colors = norm(grad_46)\n",
    "cmap = mpl.cm.get_cmap('bwr')\n",
    "colors = cmap(grad_colors)\n",
    "for i in range(100):    \n",
    "    plt.scatter(X[i],four_candidate[i],color=colors[i])    \n",
    "\n",
    "plt.plot(X,four_candidate,zorder=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T03:08:54.479991Z",
     "start_time": "2019-08-13T03:08:54.477504Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CONFUSION MATRIX PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T03:09:41.689719Z",
     "start_time": "2019-08-13T03:09:40.910809Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3,ncols=3)\n",
    "\n",
    "X = np.linspace(0,1,100)\n",
    "\n",
    "def splash_on_plot(ax, X,Y,colors,cmap = 'bwr'):\n",
    "    \n",
    "    \n",
    "    cmap = mpl.cm.get_cmap('bwr')\n",
    "    norm = mpl.colors.Normalize(vmin=min(colors), vmax=max(colors))\n",
    "    #grad_colors = norm(Y)\n",
    "    #print(X.shape)\n",
    "    #print(Y.shape)\n",
    "    segments = []\n",
    "    for i in range(len(X))[:-1]:\n",
    "        segments.append([(X[i],Y[i]) , (X[i+1],Y[i+1])])\n",
    "    #segments = np.column_stack([X, Y])\n",
    "    \n",
    "    #print(segments.shape[1])\n",
    "    coll = LineCollection(segments, cmap=mpl.cm.get_cmap('bwr'),norm=norm)\n",
    "    coll.set_array(colors)\n",
    "    ax.add_collection(coll)\n",
    "    \n",
    "##ax[0][0].plot(X,four_candidate)\n",
    "#ax[1][1].plot(X,five_candidate)\n",
    "#ax[2][2].plot(X,six_candidate)\n",
    "splash_on_plot(ax[0][0],X,four_candidate,colors=np.array(grad_44))\n",
    "splash_on_plot(ax[0][1],X,four_candidate,colors=np.array(grad_45))\n",
    "splash_on_plot(ax[0][2],X,four_candidate,colors=np.array(grad_46))\n",
    "\n",
    "splash_on_plot(ax[1][0],X,five_candidate,colors=np.array(grad_54))\n",
    "splash_on_plot(ax[1][1],X,five_candidate,colors=np.array(grad_55))\n",
    "splash_on_plot(ax[1][2],X,five_candidate,colors=np.array(grad_56))\n",
    "\n",
    "splash_on_plot(ax[2][0],X,six_candidate,colors=np.array(grad_64))\n",
    "splash_on_plot(ax[2][1],X,six_candidate,colors=np.array(grad_65))\n",
    "splash_on_plot(ax[2][2],X,six_candidate,colors=np.array(grad_66))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
